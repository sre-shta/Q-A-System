import streamlit as st
import os
from langchain.chains import ConversationChain
from langchain.chains.conversation.memory import ConversationBufferWindowMemory
from langchain.prompts import PromptTemplate
from langchain_groq import ChatGroq
from dotenv import load_dotenv
from bs4 import BeautifulSoup
import requests

# Load environment variables
load_dotenv()

groq_api_key = os.environ['GROQ_API_KEY']

def fetch_webpage_content(url):
    """Fetch and clean the content of a webpage."""
    try:
        response = requests.get(url)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            # Extract text from <p> tags (or other content as needed)
            paragraphs = soup.find_all('p')
            content = " ".join([para.get_text(strip=True) for para in paragraphs])
            return content
        else:
            return "Unable to fetch webpage content. Please check the URL."
    except Exception as e:
        return f"Error fetching webpage content: {e}"

def main():
    st.title("Question-Answering System ðŸ“š")
    st.markdown(
        """
        This application uses **Groq LLM** to answer your questions based on real-time content fetched from a webpage. 
        Currently referencing: [Reva University](https://www.reva.edu.in/)
        """
    )

    # Add customization options to the sidebar
    st.sidebar.title('Select an LLM')
    model = st.sidebar.selectbox(
        'Choose a model',
        ['mixtral-8x7b-32768', 'llama2-70b-4096']
    )
    conversational_memory_length = st.sidebar.slider('Conversational memory length:', 1, 10, value=5)

    memory = ConversationBufferWindowMemory(k=conversational_memory_length)

    # User input for question
    user_question = st.text_area("Ask a question about Reva University:")

    # Fetch webpage content
    webpage_content = fetch_webpage_content("https://www.reva.edu.in/")

    if webpage_content.startswith("Error") or webpage_content.startswith("Unable"):
        st.error(webpage_content)
        return

    # Initialize Groq Langchain chat object and conversation
    groq_chat = ChatGroq(
        groq_api_key=groq_api_key,
        model_name=model
    )

    # Define a prompt template to guide the model
    prompt_template = PromptTemplate(
        input_variables=["context", "question"],
        template=(
            "You are a helpful assistant trained to answer questions based on the provided content. "
            "Content: {context} \n\n"
            "Question: {question} \n\n"
            "Answer concisely and accurately."
        )
    )

    conversation = ConversationChain(
        llm=groq_chat,
        memory=memory
    )

    # Process the question
    if user_question:
        prompt = prompt_template.format(context=webpage_content, question=user_question)
        response = conversation(prompt)
        st.write("### Answer:", response["response"])

if __name__ == "__main__":
    main()
