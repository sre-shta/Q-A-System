# üß† Question-Answering System with LLMs

This project leverages **Large Language Models (LLMs)** to create an interactive **Question-Answering System**. It answers user queries based on a large corpus of documents, providing a seamless experience for knowledge discovery. Powered by **Streamlit** for the frontend, it uses **LangChain** and **Groq** for conversational AI, offering accurate and context-aware responses.

---

## üöÄ Features
- **Dynamic Question-Answering**: Handles user questions with conversational memory.
- **Customizable LLMs**: Supports multiple Groq models for varied performance needs.
- **Interactive UI**: Built with Streamlit for a user-friendly interface.
- **Conversational Memory**: Retains context over multiple turns.
- **API Integration**: Retrieves real-time data from external sources (e.g., [Reva University](https://www.reva.edu.in/)) for enhanced responses.

---

## üõ†Ô∏è Tech Stack
- **Frontend**: [Streamlit](https://streamlit.io/)
- **Backend**: [LangChain](https://langchain.com/), [Groq](https://groq.com/)
- **Environment Management**: [Python Dotenv](https://pypi.org/project/python-dotenv/)

---
